# A/B Testing & Experimentaci√≥n

**P√°gina padre:** Hola

---

# A/B Testing & Experimentaci√≥n
üë• Tipo de Usuario: Entrenador Personal (Administrador), Entrenador Asociado, Administrador del Sistema
Esta funcionalidad est√° dise√±ada para los roles con permisos de gesti√≥n de marketing y ventas, como el Entrenador Personal que es due√±o del negocio o un Entrenador Asociado con responsabilidades de crecimiento. No es visible para los Clientes o Leads. Permite a los usuarios optimizar sus estrategias de captaci√≥n y comunicaci√≥n bas√°ndose en datos reales en lugar de intuiciones.
üìù Nota: Esta es una especificaci√≥n/documentaci√≥n. NO incluye c√≥digo implementado, solo la especificaci√≥n de componentes y APIs que se necesitar√≠an desarrollar.
Ruta: /dashboard/marketing/ab-testing
## Descripci√≥n Funcional
El m√≥dulo de A/B Testing y Experimentaci√≥n de TrainerERP es una potente herramienta dise√±ada para que los entrenadores personales dejen de adivinar qu√© funciona y empiecen a tomar decisiones basadas en datos. Esta funcionalidad permite crear y gestionar pruebas controladas para comparar dos o m√°s versiones de un activo de marketing y determinar cu√°l rinde mejor en la consecuci√≥n de un objetivo espec√≠fico. Por ejemplo, un entrenador puede probar dos titulares diferentes en su landing page para un nuevo 'Reto de 30 D√≠as': la Versi√≥n A podr√≠a ser 'Transforma tu F√≠sico en 30 D√≠as' y la Versi√≥n B 'Pierde hasta 5kg de Grasa este Mes'. El sistema dividir√° autom√°ticamente el tr√°fico de visitantes entre ambas versiones y medir√° cu√°l de ellas consigue m√°s inscripciones. Lo mismo se aplica a las campa√±as de email, donde se pueden probar diferentes asuntos para maximizar la tasa de apertura, o a las ofertas, comparando un '20% de descuento' contra 'una sesi√≥n extra gratis' para ver qu√© incentivo atrae a m√°s clientes. La plataforma no solo muestra los resultados en tiempo real, sino que tambi√©n realiza el an√°lisis estad√≠stico, calculando la significancia para asegurar que los resultados son fiables y no producto del azar, declarando autom√°ticamente una versi√≥n 'ganadora' cuando se alcanza un umbral de confianza.
## Valor de Negocio
El valor de negocio de la experimentaci√≥n A/B para un entrenador personal es inmenso y directo: aumenta los ingresos y reduce los costes de adquisici√≥n de clientes. En un mercado competitivo, cada lead cuenta. Al optimizar sistem√°ticamente las landing pages, los emails y las ofertas, el entrenador puede aumentar significativamente sus tasas de conversi√≥n. Un aumento del 2% al 4% en la conversi√≥n de una landing page significa duplicar el n√∫mero de clientes potenciales con el mismo presupuesto de publicidad. Esto permite escalar el negocio de manera m√°s rentable. Adem√°s, esta herramienta empodera al entrenador, transform√°ndolo de un simple proveedor de servicios a un estratega de marketing sofisticado. Le permite entender profundamente la psicolog√≠a de su cliente ideal: ¬øqu√© lenguaje resuena m√°s con ellos? ¬øQu√© im√°genes les motivan? ¬øQu√© ofertas les parecen irresistibles? Este conocimiento no solo se aplica a un √∫nico test, sino que genera aprendizajes que pueden ser utilizados en todas las comunicaciones futuras, mejorando la efectividad de todo el embudo de marketing y ventas. En resumen, el A/B testing convierte el marketing en una ciencia, proporcionando un camino claro y medible para el crecimiento sostenible del negocio.
## Prioridad / Roadmap
- Impacto: medio
- Complejidad: alta
- Fase recomendada: Post-MVP
## User Stories
- Como entrenador online, quiero crear un test A/B para mi landing page de 'Programa de Entrenamiento Personalizado' para ver si un video testimonial convierte mejor que una galer√≠a de fotos de 'antes y despu√©s', para as√≠ maximizar la venta de mis planes.
- Como coach de grupos peque√±os, quiero probar dos asuntos de email diferentes para mi campa√±a de reactivaci√≥n de ex-clientes, para identificar cu√°l genera una mayor tasa de apertura y consigue que m√°s personas se reinscriban.
- Como due√±o de un estudio de entrenamiento, quiero experimentar con dos ofertas diferentes para la primera sesi√≥n ('50% de descuento' vs. 'Gratuita si contratas un plan') para entender qu√© incentivo es m√°s efectivo para convertir visitantes en clientes de largo plazo.
- Como entrenador personal, quiero que la plataforma me muestre un dashboard claro con la tasa de conversi√≥n, el nivel de confianza estad√≠stica y me notifique cuando una versi√≥n sea la ganadora clara, para no tener que interpretar datos complejos.
- Como administrador del negocio, quiero poder ver un historial completo de todos los experimentos realizados, sus resultados y los insights clave, para poder construir un 'playbook' de lo que funciona mejor con mi audiencia espec√≠fica.
## Acciones Clave
- Crear un nuevo experimento seleccionando el tipo (Landing Page, Email, Oferta).
- Configurar las variaciones (A/B) subiendo diferentes textos, im√°genes o configuraciones.
- Definir el objetivo de conversi√≥n (ej: env√≠o de formulario, clic en bot√≥n de compra, apertura de email).
- Lanzar, pausar y finalizar un experimento.
- Monitorizar el rendimiento de cada variaci√≥n en un dashboard en tiempo real.
- Visualizar el informe final con la versi√≥n ganadora y la significancia estad√≠stica.
- Aplicar la versi√≥n ganadora con un solo clic para que se convierta en la versi√≥n por defecto.
## üß© Componentes React Sugeridos
### 1. ExperimentDashboardContainer
Tipo: container | Componente principal que obtiene y gestiona el estado de todos los experimentos (activos, pausados, finalizados) del entrenador. Maneja la l√≥gica de paginaci√≥n y filtros.
Props:
- trainerId: 
- string (requerido) - ID del entrenador para obtener sus experimentos.
Estados: experimentsList, isLoading, error, activeFilter
Dependencias: axios, react-query
Ejemplo de uso:
```typescript
<ExperimentDashboardContainer trainerId='trainer-123' />
```

### 2. ExperimentResultCard
Tipo: presentational | Muestra un resumen visual de un √∫nico experimento. Compara las m√©tricas clave de cada variante y destaca a la ganadora si existe.
Props:
- experiment: 
- Experiment (requerido) - Objeto que contiene toda la informaci√≥n y resultados del experimento.
Dependencias: recharts
Ejemplo de uso:
```typescript
<ExperimentResultCard experiment={experimentData} />
```

### 3. ExperimentSetupWizard
Tipo: container | Un wizard multi-paso que gu√≠a al entrenador a trav√©s de la creaci√≥n de un nuevo experimento, desde la selecci√≥n del tipo hasta la definici√≥n de las variantes y el objetivo.
Props:
- onComplete: 
- (newExperiment: Experiment) => void (requerido) - Callback que se ejecuta cuando el wizard se completa con √©xito.
Estados: currentStep, experimentConfig, validationErrors
Dependencias: react-hook-form
Ejemplo de uso:
```typescript
<ExperimentSetupWizard onComplete={(exp) => console.log('Experimento creado:', exp)} />
```

### 4. StatisticalSignificanceIndicator
Tipo: presentational | Un peque√±o componente visual que muestra el nivel de confianza estad√≠stica de un experimento, usando colores y un porcentaje para una f√°cil interpretaci√≥n.
Props:
- confidenceLevel: 
- number (requerido) - Un valor entre 0 y 1 que representa el nivel de confianza.
Ejemplo de uso:
```typescript
<StatisticalSignificanceIndicator confidenceLevel={0.97} />
```
## üîå APIs Requeridas
### 1. POST /api/marketing/experiments
Crea un nuevo experimento de A/B testing para el entrenador autenticado.
Par√°metros:
- experimentData (
- object, body, requerido): Objeto con la configuraci√≥n del experimento, incluyendo nombre, tipo, objetivo y variantes.
Respuesta:
Tipo: object
Estructura: El objeto del experimento reci√©n creado, incluyendo su ID.
```json
{
  "id": "exp_abc123",
  "name": "Test de Headline Landing Verano",
  "type": "LANDING_PAGE",
  "status": "DRAFT",
  "variants": [
    {
      "id": "var_a",
      "name": "Versi√≥n A - Headline Original"
    },
    {
      "id": "var_b",
      "name": "Versi√≥n B - Headline Agresivo"
    }
  ],
  "createdAt": "2023-10-27T10:00:00Z"
}
```
Autenticaci√≥n: Requerida
Errores posibles:
- 400: 
- Bad Request - Datos del experimento inv√°lidos o incompletos (ej: menos de dos variantes).
- 403: 
- Forbidden - El plan del usuario no incluye la funcionalidad de A/B testing.

### 2. GET /api/marketing/experiments
Obtiene una lista paginada de todos los experimentos del entrenador.
Par√°metros:
- status (
- string, query, opcional): Filtra experimentos por estado (e.g., 'active', 'finished', 'draft').
- page (
- number, query, opcional): N√∫mero de p√°gina para la paginaci√≥n.
Respuesta:
Tipo: array
Estructura: Un array de objetos de experimento con sus resultados resumidos.
```json
[
  {
    "id": "exp_abc123",
    "name": "Test de Headline Landing Verano",
    "status": "ACTIVE",
    "winner": null,
    "confidence": 0.85,
    "startDate": "2023-10-28T10:00:00Z"
  }
]
```
Autenticaci√≥n: Requerida

### 3. GET /api/marketing/experiments/{id}
Obtiene los detalles y resultados completos de un experimento espec√≠fico.
Par√°metros:
- id (
- string, path, requerido): ID del experimento a consultar.
Respuesta:
Tipo: object
Estructura: Objeto completo del experimento con estad√≠sticas detalladas por variante.
```json
{
  "id": "exp_abc123",
  "name": "Test de Headline Landing Verano",
  "status": "ACTIVE",
  "variants": [
    {
      "id": "var_a",
      "visitors": 1024,
      "conversions": 51,
      "conversionRate": 0.05
    },
    {
      "id": "var_b",
      "visitors": 1019,
      "conversions": 68,
      "conversionRate": 0.0667
    }
  ],
  "statisticalSignificance": 0.96,
  "lift": 0.334
}
```
Autenticaci√≥n: Requerida
Errores posibles:
- 404: 
- Not Found - El experimento con el ID proporcionado no existe o no pertenece al usuario.

### 4. PUT /api/marketing/experiments/{id}/status
Actualiza el estado de un experimento (ej: para iniciarlo, pausarlo o finalizarlo).
Par√°metros:
- id (
- string, path, requerido): ID del experimento a actualizar.
- status (
- string, body, requerido): El nuevo estado: 'active', 'paused', 'finished'.
Respuesta:
Tipo: object
Estructura: El objeto del experimento actualizado.
```json
{
  "id": "exp_abc123",
  "status": "ACTIVE"
}
```
Autenticaci√≥n: Requerida
Errores posibles:
- 400: 
- Bad Request - Transici√≥n de estado no v√°lida (ej: intentar iniciar un experimento ya finalizado).
- 404: 
- Not Found - El experimento con el ID proporcionado no existe.
## Notas T√©cnicas
Colecciones backend: experiments, experiment_variants, experiment_events, experiment_results
KPIs visibles: Tasa de Conversi√≥n (por variante), N√∫mero de Visitantes/Impresiones (por variante), N√∫mero de Conversiones (por variante), Significancia Estad√≠stica (o Nivel de Confianza), Mejora Relativa (Lift) de la variante B sobre la A, Duraci√≥n del Experimento, Probabilidad de ser la Mejor (P-to-beat-baseline)
## Documentaci√≥n Completa
## Resumen
El m√≥dulo de A/B Testing y Experimentaci√≥n es una herramienta de optimizaci√≥n avanzada dentro de TrainerERP, dise√±ada para ayudar a los entrenadores a tomar decisiones de marketing basadas en datos, no en suposiciones. Su prop√≥sito es permitir la comparaci√≥n cient√≠fica de dos o m√°s versiones de un elemento (como una p√°gina de ventas, un email o una oferta) para determinar cu√°l es m√°s efectiva para lograr un objetivo concreto, como conseguir m√°s inscripciones, ventas o clics.
En lugar de preguntarse '¬øQu√© titular funcionar√° mejor para mi nuevo programa?', el entrenador puede probar dos o tres opciones simult√°neamente. El sistema divide autom√°ticamente el tr√°fico entre las versiones y recopila datos sobre el rendimiento de cada una. Al final, presenta un informe claro que no solo muestra cu√°l funcion√≥ mejor, sino que tambi√©n indica con un alto grado de confianza estad√≠stica que el resultado no es una casualidad. Esta funcionalidad transforma el marketing de un arte a una ciencia, proporcionando un m√©todo claro para mejorar continuamente las tasas de conversi√≥n, maximizar el retorno de la inversi√≥n en publicidad y, en √∫ltima instancia, hacer crecer el negocio del entrenador de manera m√°s r√°pida y predecible.
## Flujo paso a paso de uso real
Imaginemos a **Laura, una entrenadora online** que quiere lanzar un nuevo "Reto de 90 D√≠as". Ha creado una landing page, pero no est√° segura de qu√© oferta inicial atraer√° a m√°s clientes.
1. **Creaci√≥n del Experimento:** Laura accede a la secci√≥n 'A/B Testing' en TrainerERP y hace clic en 'Crear Nuevo Experimento'. Selecciona el tipo 'Landing Page'. Le da un nombre: "Test de Oferta - Reto 90 D√≠as".
2. **Definici√≥n de Variantes:**
* **Variante A (Control):** Configura la oferta principal como un "15% de descuento en el primer mes".
* **Variante B (Prueba):** Crea una copia de la p√°gina y cambia la oferta a "Incluye una sesi√≥n de coaching nutricional 1-a-1 GRATIS (valorada en 75‚Ç¨)".
3. **Configuraci√≥n del Objetivo:** Laura define el objetivo de conversi√≥n como "un env√≠o exitoso del formulario de inscripci√≥n". TrainerERP ya sabe c√≥mo rastrear esto en su constructor de p√°ginas.
4. **Lanzamiento:** Revisa la configuraci√≥n y lanza el experimento. TrainerERP comienza a dividir el tr√°fico 50/50 entre las dos versiones de la p√°gina. Los visitantes son asignados a una versi√≥n y la ver√°n consistentemente si regresan.
5. **Monitorizaci√≥n:** Durante los siguientes d√≠as, Laura visita el dashboard del experimento. Ve en tiempo real el n√∫mero de visitantes, las conversiones y la tasa de conversi√≥n para cada variante. Un 'Indicador de Significancia Estad√≠stica' le muestra qu√© tan fiables son los datos hasta el momento. Al principio, est√° bajo (ej. 60%), lo que significa que es demasiado pronto para decidir.
6. **Declaraci√≥n del Ganador:** Despu√©s de una semana, el sistema ha recopilado suficientes datos. El indicador de significancia alcanza el 97%. La Variante B (sesi√≥n gratis) muestra una tasa de conversi√≥n un 35% superior a la Variante A. El sistema marca la Variante B como la 'Ganadora'. Laura recibe una notificaci√≥n.
7. **Aplicaci√≥n de Cambios:** Con un solo clic en 'Aplicar Ganador', Laura configura la Variante B como la √∫nica versi√≥n visible de su landing page para todo el futuro tr√°fico. Ahora sabe con certeza que esta oferta es m√°s atractiva para su p√∫blico.
## Riesgos operativos y edge cases
- **'Peeking' o Espionaje de Resultados:** El riesgo m√°s com√∫n es que el entrenador revise los resultados cada hora y detenga el test en cuanto una variante parezca estar ganando. Esto puede llevar a conclusiones falsas, ya que la aleatoriedad puede hacer que una versi√≥n parezca mejor al principio. **Mitigaci√≥n:** Educar al usuario dentro de la UI para que espere a que se alcance un tama√±o de muestra m√≠nimo y una alta significancia estad√≠stica.
- **Bajo Volumen de Tr√°fico:** Si el entrenador tiene pocos visitantes, un test puede tardar semanas o meses en dar resultados fiables. **Mitigaci√≥n:** El sistema debe estimar la duraci√≥n del test bas√°ndose en el tr√°fico actual y la mejora esperada, gestionando las expectativas del usuario.
- **Efecto Regresi√≥n a la Media:** Una variante puede tener un rendimiento extraordinariamente bueno o malo al principio, pero tender√° a normalizarse con el tiempo. **Mitigaci√≥n:** Similar al 'peeking', insistir en la necesidad de esperar a que el test 'madure'.
- **M√∫ltiples Cambios a la Vez:** Si un entrenador prueba un nuevo titular Y una nueva imagen al mismo tiempo, no sabr√° cu√°l de los dos cambios fue el responsable de la mejora. **Mitigaci√≥n:** Recomendar tests A/B puros (un solo cambio) para empezar y explicar el concepto de tests multivariante como una opci√≥n avanzada.
## KPIs y qu√© significan
- **Tasa de Conversi√≥n:** El porcentaje de visitantes que completan la acci√≥n deseada (ej. se inscriben, compran, hacen clic). Es la m√©trica principal para medir la efectividad. `(Conversiones / Visitantes) * 100`.
- **Significancia Estad√≠stica:** Es el 'medidor de confianza' en los resultados. Un valor del 95% significa que hay un 95% de probabilidad de que la diferencia de rendimiento entre las variantes sea real y no producto del azar. Es crucial para tomar decisiones fiables.
- **Mejora Relativa (Lift):** Muestra cu√°nto mejor (o peor) es una variante en comparaci√≥n con la original, en porcentaje. Un 'lift' del 25% significa que la nueva versi√≥n est√° generando un 25% m√°s de conversiones.
- **Visitantes/Impresiones:** El n√∫mero total de usuarios √∫nicos que han visto cada variante. Esencial para asegurar que tenemos un tama√±o de muestra suficiente.
- **Conversiones:** El n√∫mero bruto de veces que se ha alcanzado el objetivo en cada variante.
## Diagramas de Flujo (Mermaid)
mermaid
graph TD
A[Inicio: Dashboard de A/B Testing] --> B{Crear Nuevo Experimento};
B --> C[1. Elegir Tipo: Landing Page, Email, etc.];
C --> D[2. Nombrar Experimento y Definir Objetivo];
D --> E[3. Configurar Variante A (Control)];
E --> F[4. Configurar Variante B (Prueba)];
F --> G{¬øA√±adir m√°s variantes?};
G -- S√≠ --> F;
G -- No --> H[5. Revisar y Lanzar Experimento];
H --> I[Sistema divide tr√°fico y recopila datos];
I --> J[Monitorizar Dashboard en Tiempo Real];
J --> K{¬øSignificancia > 95%?};
K -- No --> J;
K -- S√≠ --> L[Declarar Variante Ganadora];
L --> M[Usuario recibe notificaci√≥n];
M --> N{Aplicar Ganador};
N -- S√≠ --> O[La variante ganadora se convierte en la versi√≥n por defecto];
N -- No --> P[Experimento finalizado y archivado];
O --> P;
